{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-22T06:30:24.344435Z",
     "start_time": "2025-10-22T06:30:24.339383Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T06:30:24.364005Z",
     "start_time": "2025-10-22T06:30:24.358094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ],
   "id": "a7d70bf4501c9355",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T06:30:24.398084Z",
     "start_time": "2025-10-22T06:30:24.391339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загрузка и подготовка данных CIFAR-10\n",
    "def get_cifar10_data(batch_size=64):  # Уменьшил batch_size для скорости\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)  # workers=0 для скорости\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    return trainloader, testloader"
   ],
   "id": "9e7c6e472bd0abcb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T06:30:24.427575Z",
     "start_time": "2025-10-22T06:30:24.419649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_alexnet(num_classes=10):\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        if type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    net = nn.Sequential(\n",
    "        # Input: 32x32x3 (CIFAR-10)\n",
    "\n",
    "        # Layer 1\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 16x16x64\n",
    "\n",
    "        # Layer 2\n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 8x8x128\n",
    "\n",
    "        # Layer 3\n",
    "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),  # Output: 8x8x256\n",
    "\n",
    "        # Layer 4\n",
    "        nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),  # Output: 8x8x256\n",
    "\n",
    "        # Layer 5\n",
    "        nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 4x4x128\n",
    "\n",
    "        nn.Flatten(),\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(128 * 4 * 4, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "\n",
    "    net.apply(init_weights)\n",
    "    return net"
   ],
   "id": "674ccdb41bdf9379",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T06:30:24.451040Z",
     "start_time": "2025-10-22T06:30:24.441838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_alexnet(net, train_loader, device, num_epochs=20, learning_rate=0.01):  # Уменьшено до 20 эпох\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # Более частый шаг\n",
    "    acc_history = []\n",
    "\n",
    "    with tqdm(total=len(train_loader)*num_epochs, position=0, leave=True) as pbar:\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            net.train()\n",
    "            for batch_num, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Calculate batch Accuracy\n",
    "                _, predicted = outputs.max(1)\n",
    "                batch_total = labels.size(0)\n",
    "                batch_correct = predicted.eq(labels).sum().item()\n",
    "                batch_acc = batch_correct/batch_total\n",
    "\n",
    "                pbar.set_description(\"Epoch: %d, Batch: %2d, Loss: %.4f, Acc: %.2f\" %\n",
    "                                   (epoch+1, batch_num+1, running_loss/(batch_num+1), batch_acc))\n",
    "                pbar.update()\n",
    "\n",
    "                total += batch_total\n",
    "                correct += batch_correct\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the evaluation metric and reset it for the next epoch\n",
    "            epoch_acc = correct/total\n",
    "            acc_history.append(epoch_acc)\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, '\n",
    "                  f'Train Acc: {epoch_acc:.2%}')\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "    return acc_history"
   ],
   "id": "26854e561e41754d",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T06:30:24.464138Z",
     "start_time": "2025-10-22T06:30:24.458613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция оценки\n",
    "def evaluate_acc(net, test_loader, device):\n",
    "    net.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (inputs, labels) in enumerate(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    acc = correct/total\n",
    "    return acc"
   ],
   "id": "b946a9076cc548ec",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-22T06:30:24.478945Z",
     "start_time": "2025-10-22T06:30:24.472543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция визуализации\n",
    "def print_history(history, title):\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(history)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "d225ebe09699256c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-10-22T06:30:24.492248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 0.01\n",
    "\n",
    "train_dataloader, test_dataloader = get_cifar10_data(batch_size)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataloader.dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataloader.dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "\n",
    "# Создание модели\n",
    "alexnet = build_alexnet(num_classes=10)\n",
    "alexnet = alexnet.to(device)\n",
    "print(\"AlexNet architecture:\")\n",
    "print(alexnet)\n",
    "\n",
    "# Обучение \n",
    "hist_alexnet = train_alexnet(alexnet, train_dataloader, device, epochs, lr)\n",
    "\n",
    "# Оценка\n",
    "alexnet_acc = evaluate_acc(alexnet, test_dataloader, device)\n",
    "print(f'\\nTest Accuracy (AlexNet): {alexnet_acc:.2%}')\n",
    "\n",
    "# Визуализация\n",
    "print_history(hist_alexnet, \"AlexNet Model Accuracy\")"
   ],
   "id": "712e270440e6ddab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 50000\n",
      "Test samples: 10000\n",
      "Batch size: 64\n",
      "Epochs: 20\n",
      "AlexNet architecture:\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): ReLU(inplace=True)\n",
      "  (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace=True)\n",
      "  (10): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (13): Flatten(start_dim=1, end_dim=-1)\n",
      "  (14): Dropout(p=0.5, inplace=False)\n",
      "  (15): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (16): ReLU(inplace=True)\n",
      "  (17): Dropout(p=0.5, inplace=False)\n",
      "  (18): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (19): ReLU(inplace=True)\n",
      "  (20): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 174, Loss: 2.1133, Acc: 0.25:   1%|          | 174/15640 [00:44<1:05:06,  3.96it/s]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
